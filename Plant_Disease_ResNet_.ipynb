{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gVULXjAHEOy"
      },
      "outputs": [],
      "source": [
        "#IMPORTING LIBRARIES\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, ZeroPadding2D, BatchNormalization, Activation, Add, Input, Dropout, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "vgXVLy1LJEnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0ca5ff-e714-4ad2-daa3-8e1b687672a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "path=\"https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\"\n",
        "od.download(path)\n",
        "path=\"/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "plt.figure(figsize=(70,70))\n",
        "count=0\n",
        "plant_names=[]\n",
        "total_images=0\n",
        "for i in os.listdir(path):\n",
        "  count+=1\n",
        "  plant_names.append(i)\n",
        "  plt.subplot(7,7,count)\n",
        "\n",
        "  images_path=os.listdir(path+\"/\"+i)\n",
        "  print(\"Number of images of \"+i+\":\",len(images_path),\"||\",end=\" \")\n",
        "  total_images+=len(images_path)\n",
        "\n",
        "  image_show=plt.imread(path+\"/\"+i+\"/\"+images_path[0])\n",
        "\n",
        "  plt.imshow(image_show)\n",
        "  plt.xlabel(i)\n",
        "\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "print(\"Total number of images we have\",total_images)\n",
        "\n",
        "print(plant_names)\n",
        "print(len(plant_names))\n"
      ],
      "metadata": {
        "id": "XoKnCEYJHce-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bb814a-742c-416d-e29c-b0d586d813d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: aanandgnair\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "Downloading new-plant-diseases-dataset.zip to ./new-plant-diseases-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.70G/2.70G [00:26<00:00, 107MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of images of Corn_(maize)___Common_rust_: 1907 || Number of images of Potato___Early_blight: 1939 || Number of images of Tomato___Tomato_mosaic_virus: 1790 || Number of images of Soybean___healthy: 2022 || Number of images of Corn_(maize)___healthy: 1859 || Number of images of Tomato___Late_blight: 1851 || Number of images of Raspberry___healthy: 1781 || Number of images of Grape___Black_rot: 1888 || Number of images of Peach___Bacterial_spot: 1838 || Number of images of Corn_(maize)___Northern_Leaf_Blight: 1908 || Number of images of Tomato___healthy: 1926 || Number of images of Squash___Powdery_mildew: 1736 || Number of images of Apple___Black_rot: 1987 || Number of images of Tomato___Bacterial_spot: 1702 || Number of images of Tomato___Early_blight: 1920 || Number of images of Apple___Apple_scab: 2016 || Number of images of Potato___healthy: 1824 || Number of images of Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1722 || Number of images of Peach___healthy: 1728 || Number of images of Apple___healthy: 2008 || Number of images of Blueberry___healthy: 1816 || Number of images of Tomato___Leaf_Mold: 1882 || Number of images of Orange___Haunglongbing_(Citrus_greening): 2010 || Number of images of Cherry_(including_sour)___healthy: 1826 || Number of images of Strawberry___Leaf_scorch: 1774 || Number of images of Grape___Esca_(Black_Measles): 1920 || Number of images of Tomato___Target_Spot: 1827 || Number of images of Tomato___Tomato_Yellow_Leaf_Curl_Virus: 1961 || Number of images of Cherry_(including_sour)___Powdery_mildew: 1683 || Number of images of Pepper,_bell___healthy: 1988 || Number of images of Tomato___Septoria_leaf_spot: 1745 || Number of images of Pepper,_bell___Bacterial_spot: 1913 || Number of images of Potato___Late_blight: 1939 || Number of images of Tomato___Spider_mites Two-spotted_spider_mite: 1741 || Number of images of Grape___healthy: 1692 || Number of images of Strawberry___healthy: 1824 || Number of images of Apple___Cedar_apple_rust: 1760 || Number of images of Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 1642 || Total number of images we have 70295\n",
            "['Corn_(maize)___Common_rust_', 'Potato___Early_blight', 'Tomato___Tomato_mosaic_virus', 'Soybean___healthy', 'Corn_(maize)___healthy', 'Tomato___Late_blight', 'Raspberry___healthy', 'Grape___Black_rot', 'Peach___Bacterial_spot', 'Corn_(maize)___Northern_Leaf_Blight', 'Tomato___healthy', 'Squash___Powdery_mildew', 'Apple___Black_rot', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Apple___Apple_scab', 'Potato___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Peach___healthy', 'Apple___healthy', 'Blueberry___healthy', 'Tomato___Leaf_Mold', 'Orange___Haunglongbing_(Citrus_greening)', 'Cherry_(including_sour)___healthy', 'Strawberry___Leaf_scorch', 'Grape___Esca_(Black_Measles)', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Cherry_(including_sour)___Powdery_mildew', 'Pepper,_bell___healthy', 'Tomato___Septoria_leaf_spot', 'Pepper,_bell___Bacterial_spot', 'Potato___Late_blight', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Grape___healthy', 'Strawberry___healthy', 'Apple___Cedar_apple_rust', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot']\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "s1zVmtisOqCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "G03ad6hBOubD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9xiDaDrDJiWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50()\n",
        "\n",
        "headModel = base_model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=headModel)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HV4J39mNO1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet import preprocess_input"
      ],
      "metadata": {
        "id": "TV_Lq7BeO6TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the base ResNet50 model (pre-trained on ImageNet) without the top layers\n",
        "base_model_tf = ResNet50(include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "base_model_tf.trainable = False\n",
        "\n",
        "# Define the input tensor\n",
        "pt = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Apply preprocessing to the input\n",
        "x = preprocess_input(pt)\n",
        "\n",
        "# Pass the preprocessed input through the base model (with trainable=False)\n",
        "model_resnet = base_model_tf(x, training=False)\n",
        "\n",
        "# Add Global Average Pooling and classification layers\n",
        "model_resnet = GlobalAveragePooling2D()(model_resnet)\n",
        "model_resnet = Dense(128, activation='relu')(model_resnet)\n",
        "model_resnet = Dense(64, activation='relu')(model_resnet)\n",
        "model_resnet = Dense(38, activation='softmax')(model_resnet)\n",
        "\n",
        "# Create the final model\n",
        "model_main = Model(inputs=pt, outputs=model_resnet)\n",
        "\n",
        "# Print the model summary\n",
        "model_main.summary()\n"
      ],
      "metadata": {
        "id": "zQ6A-d5AQG-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image augmentation\n",
        "train_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False\n",
        "                                  ,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n",
        "\n",
        "val_datagen=ImageDataGenerator()\n",
        "\n",
        "path_train='/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "\n",
        "path_valid='/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "\n",
        "train= train_datagen.flow_from_directory(directory=path_train,batch_size=32,target_size=(224,224),\n",
        "                                         color_mode='rgb',class_mode='categorical',seed=42)\n",
        "\n",
        "valid=val_datagen.flow_from_directory(directory=path_valid,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical')"
      ],
      "metadata": {
        "id": "JFg1B8sSQ8Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CallBacks\n",
        "es=EarlyStopping(monitor='val_accuracy',verbose=1,patience=7,mode='auto')\n",
        "mc=ModelCheckpoint(filepath='/content/best_model.keras',monitor='val_accuracy',verbose=1,save_best_only=True) # Changed filepath to include a filename ending with .keras\n",
        "lr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.001)\n",
        "\n",
        "model_main = Model(inputs=pt, outputs=model_resnet)\n",
        "\n",
        "# Compile the model\n",
        "model_main.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_main.summary()"
      ],
      "metadata": {
        "id": "x5NbGZ9aRX89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "model_main.fit(train, validation_data=valid, epochs=10, steps_per_epoch=100, verbose=1, callbacks=[mc, es, lr])\n",
        "\n",
        "model_main.save(\"RESNET50_PLANT_DISEASE.h5\")"
      ],
      "metadata": {
        "id": "DW_rmaoSRvIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ad9bd4-155b-4e5c-a1d6-0f18da99073b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 49/100\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 6s/step - accuracy: 0.1064 - loss: 3.4274"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.show()\n",
        "#%matplotlib inline\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "w0fX2kdvlefa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(model_main.history.history['loss'],color='b',label='Training loss')\n",
        "plt.plot(model_main.history.history['val_loss'],color='r',label='Validation loss')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss_value\")\n",
        "plt.title(\"loss\")"
      ],
      "metadata": {
        "id": "G5Q5O6IaliYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(model_main.history.history['accuracy'],color='b',label='Training accuracy')\n",
        "plt.plot(model_main.history.history['val_accuracy'],color='r',label='Validation accsuracy')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"accuracy graph\")"
      ],
      "metadata": {
        "id": "914lbHmZlkxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x1OmqnVQlxKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/new-plant-diseases-dataset/test/test/AppleCedarRust1.JPG\"\n",
        "new_img = image.load_img(image_path, target_size=(224, 224))\n",
        "img = image.img_to_array(new_img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img / 255"
      ],
      "metadata": {
        "id": "KFVTul0Ql1Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Following is our prediction:\")\n",
        "prediction = model_main.predict(img)"
      ],
      "metadata": {
        "id": "PKY3LDvsmBzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = valid.class_indices\n",
        "predicted_class_idx = np.argmax(prediction)\n",
        "predicted_class = list(class_names.keys())[list(class_names.values()).index(predicted_class_idx)]\n"
      ],
      "metadata": {
        "id": "SMQSVA2NmKP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(new_img)\n",
        "plt.axis('off')\n",
        "plt.title(predicted_class)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hP1Ap7KJmNaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "0XHZfciYmWVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation set\n",
        "y_true = valid.classes\n",
        "y_pred_probs = model_main.predict(valid)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)"
      ],
      "metadata": {
        "id": "UNSawT11mZ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "GxqEE9I4mqsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mtx)\n"
      ],
      "metadata": {
        "id": "i6e0uvdhmw18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "class_names = list(train.class_indices.keys())"
      ],
      "metadata": {
        "id": "x-b4lHF0m0cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Umka8NsCm36C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jmoc84ujm6fz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}